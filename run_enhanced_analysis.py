#!/usr/bin/env python
"""
run_enhanced_analysis.py
Demonstrates the enhanced ML trading system with advanced features
"""

import os
import sys
import pandas as pd
import numpy as np
import logging
from datetime import datetime
import yaml
import warnings
warnings.filterwarnings('ignore')

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Import enhanced modules
from featureengineer_enhanced import EnhancedFeatureEngineer
from modeltrainer_enhanced import EnhancedModelTrainer
from modelpredictor_enhanced import EnhancedModelPredictor
from backtest_enhanced import EnhancedBacktester


def load_config(config_path='config.yaml'):
    """Load configuration file."""
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)


def load_l2_data(config):
    """Load L2 data for analysis."""
    logger.info("Loading L2 data...")
    
    # Try to load prepared data
    base_dir = config.get('base_dir', './trading_bot_data')
    safe_symbol = config.get('symbol', 'SYMBOL').replace('/', '_').replace(':', '')
    
    data_path = os.path.join(base_dir, f"prepared_data_l2_only_{safe_symbol}.csv")
    
    if os.path.exists(data_path):
        df = pd.read_csv(data_path)
        logger.info(f"Loaded {len(df)} rows from {data_path}")
        return df
    else:
        logger.error(f"Data file not found: {data_path}")
        return None


def analyze_current_model(config):
    """Analyze the current model performance."""
    logger.info("=" * 60)
    logger.info("ANALYZING CURRENT MODEL")
    logger.info("=" * 60)
    
    # Load data
    df = load_l2_data(config)
    if df is None:
        return
    
    # Basic statistics
    logger.info(f"Data shape: {df.shape}")
    logger.info(f"Data range: {df.index[0]} to {df.index[-1]}")
    
    # Check current features
    feature_cols = [col for col in df.columns if col not in ['target', 'timestamp']]
    logger.info(f"Current features: {len(feature_cols)}")
    
    # Analyze target distribution
    if 'target' in df.columns:
        target_stats = df['target'].describe()
        logger.info("\nTarget distribution:")
        logger.info(f"Mean: {target_stats['mean']:.6f}")
        logger.info(f"Std: {target_stats['std']:.6f}")
        logger.info(f"Min: {target_stats['min']:.6f}")
        logger.info(f"Max: {target_stats['max']:.6f}")
        
        # Check why threshold is so low
        percentiles = [0.6, 0.7, 0.8, 0.9, 0.95, 0.99]
        logger.info("\nTarget absolute value percentiles:")
        for p in percentiles:
            val = np.percentile(np.abs(df['target'].dropna()), p * 100)
            logger.info(f"{p*100:.0f}th percentile: {val:.4f}")
    
    logger.info("\n" + "=" * 60)


def demonstrate_enhanced_features(config):
    """Demonstrate enhanced feature engineering."""
    logger.info("=" * 60)
    logger.info("DEMONSTRATING ENHANCED FEATURES")
    logger.info("=" * 60)
    
    # Load data
    df = load_l2_data(config)
    if df is None:
        return None
    
    # Sample for demonstration
    df_sample = df.head(10000).copy()
    
    # Initialize enhanced feature engineer
    enhanced_fe = EnhancedFeatureEngineer(config)
    
    # Generate enhanced features
    logger.info("Generating enhanced features...")
    df_enhanced = enhanced_fe.generate_features(df_sample)
    
    # Compare feature sets
    original_features = [col for col in df.columns if col not in ['target', 'timestamp']]
    enhanced_features = [col for col in df_enhanced.columns if col not in original_features + ['target', 'timestamp']]
    
    logger.info(f"\nOriginal features: {len(original_features)}")
    logger.info(f"New features added: {len(enhanced_features)}")
    logger.info(f"Total features: {len(df_enhanced.columns)}")
    
    # Show some examples of new features
    logger.info("\nExamples of new features:")
    feature_groups = {
        'Flow Imbalance': [f for f in enhanced_features if 'flow_imbalance' in f],
        'Book Pressure': [f for f in enhanced_features if 'pressure' in f],
        'Stability': [f for f in enhanced_features if 'stability' in f or 'life' in f],
        'Temporal': [f for f in enhanced_features if 'momentum' in f or 'intensity' in f],
        'Advanced Volatility': [f for f in enhanced_features if 'vol' in f and f not in original_features],
        'Market Regime': [f for f in enhanced_features if 'efficiency' in f or 'trend' in f or 'range' in f]
    }
    
    for group, features in feature_groups.items():
        if features:
            logger.info(f"\n{group} ({len(features)} features):")
            for f in features[:3]:  # Show first 3
                logger.info(f"  - {f}")
    
    logger.info("\n" + "=" * 60)
    return df_enhanced


def demonstrate_enhanced_training(config, df_enhanced):
    """Demonstrate enhanced model training."""
    logger.info("=" * 60)
    logger.info("DEMONSTRATING ENHANCED MODEL TRAINING")
    logger.info("=" * 60)
    
    if df_enhanced is None:
        return None
    
    # Initialize enhanced trainer
    enhanced_trainer = EnhancedModelTrainer(config)
    
    # For demonstration, use a smaller sample
    df_train = df_enhanced.head(5000).copy()
    
    logger.info(f"Training on {len(df_train)} samples...")
    logger.info("This will train multiple models for different prediction horizons")
    logger.info("and optimize an ensemble with dynamic thresholds.")
    
    # Note: Actual training would be done here
    # result = enhanced_trainer.train(df_train)
    
    logger.info("\nEnhanced training features:")
    logger.info("- Multi-horizon predictions (1s, 5s, 10s, 30s)")
    logger.info("- Walk-forward validation")
    logger.info("- Ensemble weighting optimization")
    logger.info("- Dynamic threshold calculation")
    logger.info("- Feature importance tracking")
    
    logger.info("\n" + "=" * 60)


def demonstrate_enhanced_prediction(config):
    """Demonstrate enhanced prediction with confidence scores."""
    logger.info("=" * 60)
    logger.info("DEMONSTRATING ENHANCED PREDICTION")
    logger.info("=" * 60)
    
    # Initialize enhanced predictor
    enhanced_predictor = EnhancedModelPredictor(config)
    
    logger.info("\nEnhanced prediction features:")
    logger.info("- Ensemble predictions from multiple horizons")
    logger.info("- Confidence scoring based on:")
    logger.info("  * Distance from threshold")
    logger.info("  * Agreement among models")
    logger.info("  * Prediction stability")
    logger.info("- Dynamic threshold adjustment")
    logger.info("- Signal quality assessment")
    
    # Show example confidence calculation
    logger.info("\nExample confidence scoring:")
    logger.info("- Strong signal far from threshold: 0.85-0.95 confidence")
    logger.info("- Moderate signal near threshold: 0.50-0.70 confidence")
    logger.info("- Disagreement among models: <0.50 confidence")
    
    logger.info("\n" + "=" * 60)


def demonstrate_realistic_backtest(config):
    """Demonstrate realistic backtesting."""
    logger.info("=" * 60)
    logger.info("DEMONSTRATING REALISTIC BACKTESTING")
    logger.info("=" * 60)
    
    # Initialize enhanced backtester
    enhanced_backtester = EnhancedBacktester(config)
    
    logger.info("\nRealistic backtesting features:")
    logger.info(f"- Maker fee: {enhanced_backtester.maker_fee:.2%}")
    logger.info(f"- Taker fee: {enhanced_backtester.taker_fee:.2%}")
    logger.info("- Market impact modeling")
    logger.info("- Position sizing constraints")
    logger.info("- Minimum time between trades")
    logger.info("- Drawdown limits")
    
    logger.info("\nPerformance metrics calculated:")
    logger.info("- Total return (after all costs)")
    logger.info("- Sharpe ratio")
    logger.info("- Sortino ratio")
    logger.info("- Maximum drawdown")
    logger.info("- Win rate")
    logger.info("- Profit factor")
    
    logger.info("\n" + "=" * 60)


def summarize_improvements():
    """Summarize the improvements made."""
    logger.info("=" * 60)
    logger.info("SUMMARY OF ENHANCEMENTS")
    logger.info("=" * 60)
    
    improvements = {
        "Feature Engineering": [
            "Added 40+ advanced microstructure features",
            "Order flow imbalance across multiple time windows",
            "Book pressure metrics weighted by price distance",
            "Microstructure stability indicators",
            "Temporal pattern features",
            "Advanced volatility measures",
            "Market regime indicators"
        ],
        "Model Architecture": [
            "Multi-timeframe ensemble (1s, 5s, 10s, 30s predictions)",
            "Walk-forward validation",
            "Dynamic threshold optimization",
            "Confidence scoring system",
            "Feature importance tracking"
        ],
        "Target Engineering": [
            "Better volatility normalization",
            "Multiple prediction horizons",
            "Extreme value clipping",
            "Categorical targets for ensemble diversity"
        ],
        "Realistic Backtesting": [
            "Transaction cost modeling (maker/taker fees)",
            "Market impact estimation",
            "Position sizing constraints",
            "Risk management rules",
            "Comprehensive performance metrics"
        ]
    }
    
    for category, items in improvements.items():
        logger.info(f"\n{category}:")
        for item in items:
            logger.info(f"  âœ“ {item}")
    
    logger.info("\n" + "=" * 60)
    logger.info("EXPECTED IMPROVEMENTS")
    logger.info("=" * 60)
    
    logger.info("1. Reduced false signals through:")
    logger.info("   - Better feature engineering capturing market microstructure")
    logger.info("   - Ensemble predictions reducing noise")
    logger.info("   - Confidence filtering of low-quality signals")
    
    logger.info("\n2. More appropriate thresholds through:")
    logger.info("   - Dynamic adjustment based on volatility")
    logger.info("   - Better target normalization")
    logger.info("   - Multi-horizon prediction averaging")
    
    logger.info("\n3. Realistic performance expectations through:")
    logger.info("   - Proper transaction cost accounting")
    logger.info("   - Market impact modeling")
    logger.info("   - Risk-adjusted position sizing")
    
    logger.info("\n" + "=" * 60)


def main():
    """Main demonstration function."""
    logger.info("ENHANCED ML TRADING SYSTEM ANALYSIS")
    logger.info("=" * 60)
    logger.info(f"Started: {datetime.now()}")
    
    # Load configuration
    config = load_config()
    
    # 1. Analyze current model
    analyze_current_model(config)
    
    # 2. Demonstrate enhanced features
    df_enhanced = demonstrate_enhanced_features(config)
    
    # 3. Demonstrate enhanced training
    demonstrate_enhanced_training(config, df_enhanced)
    
    # 4. Demonstrate enhanced prediction
    demonstrate_enhanced_prediction(config)
    
    # 5. Demonstrate realistic backtesting
    demonstrate_realistic_backtest(config)
    
    # 6. Summarize improvements
    summarize_improvements()
    
    logger.info(f"\nCompleted: {datetime.now()}")
    logger.info("=" * 60)


if __name__ == "__main__":
    main()